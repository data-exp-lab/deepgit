{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400418bc-83cd-42c1-98de-c783c6787ad0",
   "metadata": {},
   "source": [
    "# DeepGit: Building Edges one Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a1526-c70a-43ef-933e-898e3035f978",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7df1303-580c-4488-a0b3-f0c5bad1b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63a5cb5-187e-46f6-8c3f-945d9598ac11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d77c45-34e4-4096-83ce-c8d421215693",
   "metadata": {},
   "source": [
    "### GitHub Authenticate Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987c520-eb1f-44dd-92fe-7bb4b70ef475",
   "metadata": {},
   "source": [
    "Create a `.env` file in the root directory and add the line `GITHUB_TOKEN = \"your_token\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c133bcc4-71ce-44c6-9558-6a3f07990203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_github(token):\n",
    "    \"\"\"\n",
    "    Returns headers required for GitHub API requests.\n",
    "    The Accept header includes the preview for topics.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Authorization': f'token {token}',\n",
    "        'Accept': 'application/vnd.github.mercy-preview+json'\n",
    "    }\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = authenticate_github(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbcaf7-a703-4a35-89a7-5dace41a732e",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8f7a4-dee5-4114-be8a-1f5c0aac753e",
   "metadata": {},
   "source": [
    "### GitHub Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca789b34-3928-4e7e-a962-eb751c905cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_github_repos_by_topic(tag, headers):\n",
    "    \"\"\"\n",
    "    Searches GitHub repositories that have the specified topic (tag) and over 100 stars.\n",
    "    Handles pagination and returns a list of dictionaries containing only the repository name and repo id.\n",
    "    \"\"\"\n",
    "    repos = []\n",
    "    page = 1\n",
    "    per_page = 100\n",
    "    query = f\"topic:{tag} stars:>10\"\n",
    "    \n",
    "    while True:\n",
    "        url = (\n",
    "            f\"https://api.github.com/search/repositories?q={query}\"\n",
    "            f\"&sort=stars&order=desc&per_page={per_page}&page={page}\"\n",
    "        )\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching repositories for tag '{tag}': {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        items = data.get('items', [])\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        for item in items:\n",
    "            repos.append(\n",
    "                 item.get(\"full_name\")\n",
    "            )\n",
    "\n",
    "        # Break if fewer than 'per_page' items were returned (i.e. last page)\n",
    "        if len(items) < per_page:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return repos\n",
    "\n",
    "def get_repo_topics(full_name, headers):\n",
    "    \"\"\"\n",
    "    Fetches the topics (tags) of a repository given its full name.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('names', [])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160a51a-f755-466b-9444-ffd54601babb",
   "metadata": {},
   "source": [
    "### Tag Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353d5e38-1e3f-44c8-86b4-388e29addd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic_similarities(model_name: str, given_topic: str, topic_pool: list, threshold: float = 0.8):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between a given topic and a pool of topics, filtering by a threshold.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the SentenceTransformer model (e.g., 'all-MiniLM-L6-v2').\n",
    "        given_topic (str): The topic to compare against the pool.\n",
    "        topic_pool (list): List of topics to compare.\n",
    "        threshold (float): Minimum similarity score to be included in the results (default: 0.8).\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of (topic, similarity) tuples in descending order of similarity.\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Encode the given topic and the pool of topics\n",
    "    given_embedding = model.encode([given_topic])\n",
    "    pool_embeddings = model.encode(topic_pool)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity(given_embedding, pool_embeddings)[0]\n",
    "    \n",
    "    # Pair topics with their similarity scores\n",
    "    topic_similarity_pairs = [topic for topic, sim in zip(topic_pool, similarities) if sim >= threshold]\n",
    "    \n",
    "    # Sort topics by similarity (higher is better)\n",
    "    topic_similarity_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return topic_similarity_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7515eb-4349-45c9-a981-0855c65f790b",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e844143-91e1-4d72-9bbe-43e2bd71011b",
   "metadata": {},
   "source": [
    "### Input Tag(Topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb42a8b-7215-4253-9355-7245636f7a03",
   "metadata": {},
   "source": [
    "Suppose we have a topic `visual programming`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97151995-3904-4f13-b70e-6ab07f92d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_topic = \"visual-programming\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e7a95-28af-4f11-867e-74789eb59bfc",
   "metadata": {},
   "source": [
    "### Git the Initial Repos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae9deb-5269-4e55-8143-cad2435e22b2",
   "metadata": {},
   "source": [
    "**Note**: for demonstration Purpose, we only extract repos have more than 10 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb99b59-31b8-4c52-b0fc-d6a7c6e55efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_with_input_topic = search_github_repos_by_topic(input_topic, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f62ffc-0bbe-455a-bee6-7f037a614fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos_with_input_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77f07be-64a3-4451-a0b5-eda00884fc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EvgSkv/logica',\n",
       " 'triska/the-power-of-prolog',\n",
       " 'SWI-Prolog/swipl-devel',\n",
       " 'souffle-lang/souffle',\n",
       " 'noprompt/meander',\n",
       " 'composewell/streamly',\n",
       " 'opencog/atomspace',\n",
       " 'CoNarrative/precept',\n",
       " 'ichiban/prolog',\n",
       " 'potassco/clingo',\n",
       " 'ekzhang/percival',\n",
       " 'tau-prolog/tau-prolog',\n",
       " 'NucleoidAI/Nucleoid',\n",
       " 'yuce/pyswip',\n",
       " 'ekzhang/crepe',\n",
       " 's-arash/ascent',\n",
       " 'slovnicki/pLam',\n",
       " 'LogtalkDotOrg/logtalk3',\n",
       " 'alexanyernas/Ejercicios-Practicos',\n",
       " 'prove-rs/z3.rs',\n",
       " 'Shen-Language/shen-sources',\n",
       " 'i-am-tom/holmes',\n",
       " 'SHI-Yu-Zhe/awesome-agi-cocosci',\n",
       " 'ciao-lang/ciao',\n",
       " 'LukasZahradnik/PyNeuraLogic',\n",
       " 'logictensornetworks/logictensornetworks',\n",
       " 'google/neural-logic-machines',\n",
       " 'c-cube/datalog',\n",
       " 'SuperDisk/tar.pl',\n",
       " 'HackerFoo/poprc',\n",
       " 'grafana/thema',\n",
       " 'luc-tielen/eclair-lang',\n",
       " 'lab-v2/pyreason',\n",
       " 'pythological/kanren',\n",
       " 'mdiep/Logician',\n",
       " 'mcsoto/cosmos',\n",
       " 'ztangent/Julog.jl',\n",
       " 'HarvardPL/formulog',\n",
       " 'go-air/gini',\n",
       " 'fogfish/datalog',\n",
       " 'SAKET-SK/Programming-Aptitude-Interview-Prep',\n",
       " 'FLHonker/Awesome-Neural-Logic',\n",
       " 'thuwzy/Neural-Symbolic-and-Probabilistic-Logic-Papers',\n",
       " 'MNoorFawi/pytholog',\n",
       " 'JCumin/Brachylog',\n",
       " 'AmziLS/AmziProlog',\n",
       " 'knowsys/nemo',\n",
       " 'ParhamP/Natural_Logic_Interpreter',\n",
       " 'namin/logically',\n",
       " 'ekzhang/ukanren-rs',\n",
       " 'Lexpedite/blawx',\n",
       " 'robsimmons/dusa',\n",
       " 'GustikS/NeuraLogic',\n",
       " 'tuProlog/2p-kt',\n",
       " 'engboris/stellogen',\n",
       " 'aartikis/RTEC',\n",
       " 'sebdumancic/pylo2',\n",
       " 'Bodigrim/logict',\n",
       " 'hylang/hydiomatic',\n",
       " 'trealla-prolog/go',\n",
       " 'wernsey/Jatalog',\n",
       " 'ianthehenry/mixologician',\n",
       " 'microsoft/Guan',\n",
       " 'jaalonso/Lecturas_GLC',\n",
       " 'cicada-lang/chimera',\n",
       " 'friguzzi/cplint',\n",
       " 'jdormit/sicp-logic',\n",
       " 'MatthiasNickles/diff-SAT',\n",
       " 'lorenzosinisi/retex',\n",
       " 'kyouko-taiga/LogicKit',\n",
       " 'alpha-asp/Alpha',\n",
       " 'HarvardPL/AbcDatalog',\n",
       " 'acharal/hopes',\n",
       " 'davidallysson/logica-de-programacao',\n",
       " 'huangyz0918/TankLogo',\n",
       " 'pythological/unification',\n",
       " 'guregu/trealla-js',\n",
       " 'UberPyro/prowl',\n",
       " 'hemansnation/Python-For-Data-Professionals',\n",
       " 'sdleffler/whisper',\n",
       " 'norswap/prolog-dry',\n",
       " 'awalterschulze/gominikanren',\n",
       " 'namin/scalogno',\n",
       " 'AAAI-DISIM-UnivAQ/DALI',\n",
       " 'AyeshaShaukat/Project-Battle-Ships-Game',\n",
       " 'dirkschumacher/logician',\n",
       " 'ilaspltd/ILASP-releases',\n",
       " 'chessai/hsdatalog',\n",
       " 'ana-molinos/fund_prog',\n",
       " 'namin/clpsmt-miniKanren',\n",
       " 'ErgoAI/ErgoEngine',\n",
       " 'LAMDASZ-ML/Awesome-Neuro-Symbolic-Learning-with-LLM',\n",
       " 'billhails/PyScheme',\n",
       " 'namin/metamk',\n",
       " 'lps-js/lps-studio',\n",
       " 'fwcd/curry-language-server',\n",
       " 'prismplp/prism',\n",
       " 'lab-v2/pyreason-gym',\n",
       " 'retrofor/iamai',\n",
       " 'Kushal997-das/Pattern_Printing',\n",
       " 'kuba--/ut',\n",
       " 'DeMaCS-UNICAL/LoIDE',\n",
       " 'rntz/minikanren-datalog',\n",
       " 'maciej-nowak/DP-Film-Expert-System',\n",
       " 'CompSciCabal/reading-material',\n",
       " 'StrykerKKD/Logical',\n",
       " 'sarthak268/Embedded_Logic_and_Design',\n",
       " 'nuric/deeplogic',\n",
       " 'MaximovInk/NodeLogic',\n",
       " 'marcincuber/modal_logic',\n",
       " 'namin/clpset-miniKanren',\n",
       " 'jariazavalverde/fasill',\n",
       " 'AndreaInfUFSM/elc117-2024b',\n",
       " 'Jaraxxus-Me/LogiCity',\n",
       " 'eshelyaron/debug_adapter',\n",
       " 'thautwarm/RSolve',\n",
       " 'gooofy/zamia-prolog',\n",
       " 'Es1chUbJyan9/32bit_Quine-McCluskey_and_Petrick_Method_in_C',\n",
       " 'arcadio/data-logic',\n",
       " 'microsoft/service-fabric-healer',\n",
       " 'DevOgabek/LeetCodePythonSolutions',\n",
       " 'acharal/wam',\n",
       " 'xieyuheng/logic-db',\n",
       " 'DeMaCS-UNICAL/Angry-HEX',\n",
       " 'CapelliC/hitchhicker-prolog',\n",
       " 'kamel-usp/dpasp',\n",
       " 'Periklismant/oPIEC',\n",
       " 'RichardMoot/LinearOne',\n",
       " 'Innocentsax/DSA_IN_JAVA',\n",
       " 'amr205/Introduccion-a-la-IA---Libro',\n",
       " 'mountain/knowledge',\n",
       " 'fatho/logru',\n",
       " 'Sintrastes/Montague',\n",
       " 'TSG405/C-for-Everyone-Programming-Fundamentals',\n",
       " 'sdiehl/haskell-picosat',\n",
       " 'aditeyabaral/DDCO-Lab-UE18CS207',\n",
       " 'logicmoo/CYC_JRTL_with_CommonLisp',\n",
       " 'pchampio/othello-prolog',\n",
       " 'timoniq/laurelang',\n",
       " 'AppliedLogicSystems/ALSProlog',\n",
       " 'joshuaguerin/Answer-Set-Programming-Algorithms',\n",
       " 'lambduli/minilog',\n",
       " 'awto/mfjs-logic',\n",
       " 'ostis-ai/scl-machine',\n",
       " 'arasgungore/NandGame',\n",
       " 'bramucas/xclingo2',\n",
       " 'linkml/linkml-datalog',\n",
       " 'alejandroaperez1994g/js-shopping-wizard',\n",
       " 'Herb-AI/HerbSWIPL.jl',\n",
       " 'garciparedes/prolog-examples',\n",
       " 'terohuttunen/proto-vulcan',\n",
       " 'Ducasse/SOUL',\n",
       " 'MuhammadSulaiman001/prolog-lab',\n",
       " 'mdiep/Kanren.swift',\n",
       " 'xieyuheng/exo',\n",
       " 'evertheylen/logicpy',\n",
       " 'danyvarghese/PyGol',\n",
       " 'kanugurajesh/RAG-Gemini',\n",
       " 'pipe01/LogicScript',\n",
       " 'LambdaAlpha/airlang_rs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_with_input_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129f013-08c4-42d4-94cb-6a8a11aefa94",
   "metadata": {},
   "source": [
    "### Get the Pool of Topics\n",
    "\n",
    "Now we have a set of repos and we can extract the pool of topics from these repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df4cf2f-819d-4e0f-92e4-ca0950a3de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pool = []\n",
    "for full_name in repos_with_input_topic:\n",
    "    topic_pool = topic_pool + get_repo_topics(full_name, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ed2ac9-4669-4c31-b4c5-a9147faa2cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee7dd2c-6d61-467f-9801-114e446baa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pool_rm_dup = list(set(topic_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ab94fb-d0f1-4fc4-b649-88dffd2f1fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wikidata',\n",
       " 'lambda',\n",
       " 'streaming',\n",
       " 'expert-system',\n",
       " 'concatenative',\n",
       " 'competitive-programming',\n",
       " 'concurrent',\n",
       " 'java',\n",
       " 'charts',\n",
       " 'graph-database']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_pool_rm_dup[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684604fa-7990-40f0-88b8-65feb0dc2f61",
   "metadata": {},
   "source": [
    "### Further Process the Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119a629-950e-450b-a7e1-41fd6468b97b",
   "metadata": {},
   "source": [
    "Note:We probably should do this again and again to ensure that the list of tags is thorough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857baa1e-a9a2-4afa-a5b7-4c6222915af6",
   "metadata": {},
   "source": [
    "**Step1: Frequency Fiter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13708bc8-e866-4475-92ee-337fabea61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = Counter(topic_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd222f1f-2b31-4488-88b4-3d862360bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_topic_counts = {topic: count for topic, count in topic_counts.items() if count >= 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27008a67-c035-4f92-99eb-fd8ad3dfef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datalog',\n",
       " 'language',\n",
       " 'prolog-implementation',\n",
       " 'prolog',\n",
       " 'logic-programming',\n",
       " 'constraints',\n",
       " 'swi-prolog',\n",
       " 'unification',\n",
       " 'haskell',\n",
       " 'declarative-programming',\n",
       " 'interpreter',\n",
       " 'answer-set-programming',\n",
       " 'javascript',\n",
       " 'prolog-programming-language',\n",
       " 'logic',\n",
       " 'python',\n",
       " 'artificial-intelligence',\n",
       " 'rust',\n",
       " 'programming-language',\n",
       " 'functional-programming',\n",
       " 'compiler',\n",
       " 'machine-learning',\n",
       " 'minikanren']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filtered_topic_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b90d4-8841-4dba-8893-d917f036453d",
   "metadata": {},
   "source": [
    "**Step2: Similarity Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e232fed8-ff9c-42a9-a3fd-2475b4bf6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "similar_topics = compute_topic_similarities(model_name, input_topic, list(filtered_topic_counts.keys()), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d61e931-d058-4c22-aaf9-4ef3fe3fff80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c4a820e-a726-4cb9-9cfa-2a40aa0bbd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swi-prolog',\n",
       " 'functional-programming',\n",
       " 'prolog-implementation',\n",
       " 'prolog',\n",
       " 'prolog-programming-language',\n",
       " 'programming-language',\n",
       " 'logic-programming',\n",
       " 'logic',\n",
       " 'answer-set-programming',\n",
       " 'declarative-programming']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd995af5-f235-43ac-b96e-4ce6c82747a4",
   "metadata": {},
   "source": [
    "**Step3: Mannually Craft(Human in the Loop)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6a3d499-04c5-4691-805f-9540e69385a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_topics = ['swi-prolog',\n",
    " 'prolog-implementation',\n",
    " 'prolog',\n",
    " 'prolog-programming-language',\n",
    " 'logic-programming',\n",
    " 'logic',\n",
    " 'answer-set-programming',\n",
    " 'declarative-programming'\n",
    " 'datalog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44671b18-213a-4b9b-9cb1-3a6d37762b1d",
   "metadata": {},
   "source": [
    "### Get All Possible Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14114ea0-4528-454b-b77f-f43df2a33b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_repos = [ ]\n",
    "for topic in similar_topics:\n",
    "    ls_repos = search_github_repos_by_topic(topic, headers)\n",
    "    final_list_repos = final_list_repos + ls_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d142759-3c3a-4b26-98f3-b7d5fc0057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_rm_dup = list(set(final_list_repos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b755ce0-43ca-4822-8c3a-a62402b57821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list_rm_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fcec34-e625-4019-a83b-148f8b43dba4",
   "metadata": {},
   "source": [
    "### Extract Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b80eb019-9882-46b9-a01b-dd083b3cb326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repo_data = []\n",
    "for repo in final_list_rm_dup:\n",
    "    topics = get_repo_topics(repo, headers)\n",
    "    repo_data.append({\n",
    "        'repo_name': repo,\n",
    "        'topics': topics  # This could be a list, string, etc., depending on your function output\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df_repos = pd.DataFrame(repo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "694ad4e9-0d20-4a70-97f1-680846dab56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos = pd.DataFrame(repo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51ddf1f3-6c86-4895-b289-187df710320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos.to_csv(\"logic_tag_repos.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
