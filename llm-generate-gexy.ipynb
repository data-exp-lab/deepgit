{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80644cf0-a91b-4c40-aed5-e599f30007e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/1sclynnd7wv3_b5qnnqt9dyr0000gn/T/ipykernel_41370/1574412783.py:93: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab20\", num_clusters)  # Use \"tab15\" colormap for 15 distinct colors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dominant Topic for Each of the Top 15 Clusters ===\n",
      "Cluster 0: nlp\n",
      "Cluster 1: chatbot\n",
      "Cluster 2: ai\n",
      "Cluster 3: ai\n",
      "Cluster 4: python\n",
      "Cluster 5: mbr\n",
      "Cluster 6: 3d-object-detection\n",
      "Cluster 7: structured-generation\n",
      "Cluster 8: obsidian\n",
      "Cluster 9: nature-medicine\n",
      "Cluster 10: commercial\n",
      "Cluster 11: reactjs\n",
      "Cluster 12: grasp-dataset\n",
      "Cluster 13: model-diagnostics\n",
      "Cluster 14: lattice-gauge-theory\n",
      "GEXF file created: temp/llm_clusters.gexf with cluster, category, color, URL, and star count attributes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from networkx.algorithms import community\n",
    "import matplotlib.pyplot as plt  # For color mapping\n",
    "\n",
    "# Define similar topics\n",
    "similar_topics = { \"large-language-models\",\n",
    "    \"large-language-model\",\n",
    "    \"llm\",\n",
    "    \"llms\",\n",
    "    \"foundation-model\",\n",
    "    \"foundation-models\",\n",
    "    \"generative-ai\",\n",
    "    \"language-model\",\n",
    "    \"llm-inference\",\n",
    "    \"multimodal-large-language-models\",\n",
    "    'gpt',\n",
    "    'llama',\n",
    "    'llama2',\n",
    "    'openai',\n",
    "    'chatgpt',\n",
    "    'generative-ai',\n",
    "    'multimodal',\n",
    "    'gpt-4',\n",
    "    'retrieval-augmented-generation',\n",
    "    'chain-of-thought',\n",
    "    'prompt-engineering',\n",
    "    'langchain',\n",
    "    'llm-agent'}\n",
    "\n",
    "# Load repository data\n",
    "df_repos = pd.read_csv(\"temp/llm_kb.csv\")\n",
    "\n",
    "# Create an undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with topics, URL, and stars as attributes\n",
    "for idx, row in df_repos.iterrows():\n",
    "    repo = row['full_name']\n",
    "    topics = row['topics']\n",
    "    url = f\"https://github.com/{repo}\"  # Repository URL\n",
    "    stars = row['stargazers_count']  # Star count\n",
    "\n",
    "    if isinstance(topics, str) and topics.startswith(\"[\") and topics.endswith(\"]\"):\n",
    "        topics = ast.literal_eval(topics)  # Convert string list to actual list\n",
    "    elif isinstance(topics, str):\n",
    "        topics = [topics]  # Convert single topic string to list\n",
    "\n",
    "    topics_cleaned = {t.strip().lower() for t in topics}  # Clean and deduplicate topics\n",
    "    G.add_node(repo, topics=\",\".join(sorted(topics_cleaned)), url=url, stars=stars)  # Store attributes\n",
    "\n",
    "# Add edges based on shared topics\n",
    "repos = list(G.nodes)\n",
    "for repo1, repo2 in combinations(repos, 2):\n",
    "    topics1 = set(G.nodes[repo1]['topics'].split(\",\"))\n",
    "    topics2 = set(G.nodes[repo2]['topics'].split(\",\"))\n",
    "\n",
    "    shared_topics = topics1 & topics2\n",
    "    relevant_shared_topics = shared_topics & similar_topics\n",
    "    non_relevant_shared_topics = shared_topics - similar_topics\n",
    "\n",
    "    if (len(relevant_shared_topics) >= 1) and (len(non_relevant_shared_topics) >= 1):\n",
    "        G.add_edge(repo1, repo2, shared_topics=\",\".join(sorted(non_relevant_shared_topics)))\n",
    "\n",
    "# Perform Louvain community detection (clusters repos by non-similar topics)\n",
    "louvain_communities = community.louvain_communities(G, weight=None, resolution=1.0)\n",
    "top_clusters = sorted(louvain_communities, key=len, reverse=True)[:15]  # Select top 15 largest clusters\n",
    "\n",
    "# Extract dominant topics and assign clusters\n",
    "cluster_topics = {}\n",
    "\n",
    "for i, cluster in enumerate(top_clusters):\n",
    "    topic_counter = Counter()\n",
    "    \n",
    "    for repo in cluster:\n",
    "        non_similar_topics = set(G.nodes[repo]['topics'].split(\",\")) - similar_topics\n",
    "        topic_counter.update(non_similar_topics)\n",
    "\n",
    "    # Get the most common topic in this cluster (dominant topic)\n",
    "    dominant_topic = topic_counter.most_common(1)[0][0] if topic_counter else \"Unknown\"\n",
    "    cluster_topics[i] = dominant_topic  \n",
    "\n",
    "    # Assign dominant topic and cluster ID to each node\n",
    "    for repo in cluster:\n",
    "        G.nodes[repo][\"category\"] = dominant_topic\n",
    "        G.nodes[repo][\"cluster_id\"] = i  \n",
    "\n",
    "# Generate distinct colors for clusters\n",
    "num_clusters = len(top_clusters)\n",
    "colors = plt.cm.get_cmap(\"tab20\", num_clusters)  # Use \"tab15\" colormap for 15 distinct colors\n",
    "\n",
    "# Assign colors to clusters\n",
    "cluster_colors = {\n",
    "    i: f\"#{int(colors(i)[0]*255):02x}{int(colors(i)[1]*255):02x}{int(colors(i)[2]*255):02x}\" \n",
    "    for i in range(num_clusters)\n",
    "}\n",
    "\n",
    "# Assign color attribute to each node\n",
    "for i, cluster in enumerate(top_clusters):\n",
    "    for repo in cluster:\n",
    "        G.nodes[repo][\"color\"] = cluster_colors[i]  # Assign cluster color\n",
    "\n",
    "# Print Cluster Topics\n",
    "print(\"\\n=== Dominant Topic for Each of the Top 15 Clusters ===\")\n",
    "for cluster_id, topic in cluster_topics.items():\n",
    "    print(f\"Cluster {cluster_id}: {topic}\")\n",
    "\n",
    "# Write the graph to a GEXF file\n",
    "output_file = \"temp/llm_clusters.gexf\"\n",
    "nx.write_gexf(G, output_file)\n",
    "print(f\"GEXF file created: {output_file} with cluster, category, color, URL, and star count attributes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
