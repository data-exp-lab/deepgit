{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80644cf0-a91b-4c40-aed5-e599f30007e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'artificial-intelligence'\", \"'autonomous-agents'\", \"'gpt-4'\", \"'ai'\", \"'python'\", \"'openai'\"}\n",
      "{\"'bert'\", \"'natural-language-processing'\", \"'transformer'\", \"'nlp'\", \"'tensorflow'\", \"'pytorch-transformers'\", \"'pytorch'\", \"'nlp-library'\", \"'language-model'\", \"'language-models'\"}\n",
      "{\"'chatgpt'\", \"'language'\", \"'chatbot'\", \"'chatgpt-api'\", \"'bots'\"}\n",
      "{\"'ollama'\", \"'gemma'\", \"'golang'\", \"'mistral'\", \"'llama2'\", \"'go'\", \"'llama'\", \"'llms'\", \"'llama3'\", \"'llm'\"}\n",
      "{\"'chatgpt'\", \"'react'\", \"'desktop'\", \"'tauri'\", \"'nextjs'\", \"'webui'\", \"'cross-platform'\", \"'tauri-app'\", \"'vercel'\", \"'gemini'\"}\n",
      "{\"'ai-chat'\", \"'llm-inference'\"}\n",
      "{\"'llama'\", \"'ggml'\"}\n",
      "{\"'chatgpt'\", \"'gpt-4'\", \"'large-language-models'\", \"'academic'\", \"'chatglm-6b'\"}\n",
      "{\"'gpt'\", \"'llms'\", \"'chatgpt'\", \"'generativeai'\", \"'ai'\", \"'generative-ai'\", \"'azure'\", \"'openai'\", \"'prompt-engineering'\", \"'dall-e'\"}\n",
      "{\"'gpt'\", \"'chatgpt'\", \"'chatgpt4'\", \"'gpt-4'\", \"'gpt4-api'\", \"'gpt4'\", \"'gpt-3'\", \"'openai'\", \"'gpt3'\", \"'chatgpt-4'\"}\n",
      "\n",
      "=== Dominant Topic for Each of the Top 15 Clusters ===\n",
      "Cluster 0: 'artificial-intelligence'\n",
      "Cluster 1: 'bert'\n",
      "Cluster 2: 'chatgpt'\n",
      "Cluster 3: 'ollama'\n",
      "Cluster 4: 'chatgpt'\n",
      "Cluster 5: 'ai-chat'\n",
      "Cluster 6: 'llama'\n",
      "Cluster 7: 'chatgpt'\n",
      "Cluster 8: 'gpt'\n",
      "Cluster 9: 'gpt'\n",
      "GEXF file created: temp/llm_clusters_github.gexf with cluster, category, color, URL, stars, watchers, forks, primaryLanguage, isFork, isArchived, and license attributes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/t4rplfts52v8_xqb4_gx62f00000gn/T/ipykernel_7734/1460902796.py:119: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab20\", num_clusters)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from networkx.algorithms import community\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define similar topics\n",
    "similar_topics = { \"large-language-models\",\n",
    "    \"large-language-model\",\n",
    "    \"llm\",\n",
    "    \"llms\",\n",
    "    \"foundation-model\",\n",
    "    \"foundation-models\",\n",
    "    \"generative-ai\",\n",
    "    \"language-model\",\n",
    "    \"llm-inference\",\n",
    "    \"multimodal-large-language-models\",\n",
    "    'gpt',\n",
    "    'llama',\n",
    "    'llama2',\n",
    "    'openai',\n",
    "    'chatgpt',\n",
    "    'generative-ai',\n",
    "    'multimodal',\n",
    "    'gpt-4',\n",
    "    'retrieval-augmented-generation',\n",
    "    'chain-of-thought',\n",
    "    'prompt-engineering',\n",
    "    'langchain',\n",
    "    'llm-agent',\n",
    "    'ai'}\n",
    "\n",
    "# Load repository data\n",
    "df_repos = pd.read_csv(\"temp/llm_kb_github.csv\")[0:10]\n",
    "\n",
    "# Create an undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with topics, URL, stars, and additional attributes\n",
    "for idx, row in df_repos.iterrows():\n",
    "    repo = row['nameWithOwner']\n",
    "    topics = row['topics'].replace(\"[\",\"\").replace(\"]\",\"\").split(\" \")\n",
    "    url = f\"https://github.com/{repo}\"  # Repository URL\n",
    "    stars = row['stars']  # Star count\n",
    "    \n",
    "    # Additional attributes\n",
    "    additional_attrs = {}\n",
    "    for attr in ['watchers', 'forks', 'primaryLanguage', 'isFork', 'isArchived', 'license']:\n",
    "        if attr in row:\n",
    "            additional_attrs[attr] = row[attr]\n",
    "    \n",
    "    # Handle different topic formats\n",
    "    if isinstance(topics, str) and topics.startswith(\"[\") and topics.endswith(\"]\"):\n",
    "        topics = ast.literal_eval(topics)  # Convert string list to actual list\n",
    "        print(topics)\n",
    "    elif isinstance(topics, str):\n",
    "        topics = [topics]  # Convert single topic string to list\n",
    "    elif isinstance(topics, np.ndarray):\n",
    "        topics = topics.tolist()  # Convert numpy array to list\n",
    "    else:\n",
    "        # Handle any other array-like format\n",
    "        topics = list(topics)\n",
    "\n",
    "    topics_cleaned = {t.strip().lower() for t in topics}  # Clean and deduplicate topics\n",
    "\n",
    "    print(topics_cleaned)\n",
    "    # Add node with all attributes\n",
    "    node_attrs = {\n",
    "        'topics': \",\".join(sorted(topics_cleaned)), \n",
    "        'url': url, \n",
    "        'stars': stars\n",
    "    }\n",
    "    # Add the additional attributes\n",
    "    node_attrs.update(additional_attrs)\n",
    "    G.add_node(repo, **node_attrs)\n",
    "\n",
    "# Rest of the code remains the same\n",
    "# Add edges based on shared topics\n",
    "repos = list(G.nodes)\n",
    "for repo1, repo2 in combinations(repos, 2):\n",
    "    topics1 = set(G.nodes[repo1]['topics'].split(\",\"))\n",
    "    topics2 = set(G.nodes[repo2]['topics'].split(\",\"))\n",
    "\n",
    "    shared_topics = topics1 & topics2\n",
    "    relevant_shared_topics = shared_topics & similar_topics\n",
    "    non_relevant_shared_topics = shared_topics - similar_topics\n",
    "\n",
    "    if (len(relevant_shared_topics) >= 2) and (len(non_relevant_shared_topics) >= 2):\n",
    "        G.add_edge(repo1, repo2, shared_topics=\",\".join(sorted(non_relevant_shared_topics)))\n",
    "\n",
    "# Perform Louvain community detection (clusters repos by non-similar topics)\n",
    "louvain_communities = community.louvain_communities(G, weight=None, resolution=1.0)\n",
    "top_clusters = sorted(louvain_communities, key=len, reverse=True)[:15]  # Select top 15 largest clusters\n",
    "\n",
    "# Extract dominant topics and assign clusters\n",
    "cluster_topics = {}\n",
    "\n",
    "for i, cluster in enumerate(top_clusters):\n",
    "    topic_counter = Counter()\n",
    "    \n",
    "    for repo in cluster:\n",
    "        non_similar_topics = set(G.nodes[repo]['topics'].split(\",\")) - similar_topics\n",
    "        topic_counter.update(non_similar_topics)\n",
    "\n",
    "    # Get the most common topic in this cluster (dominant topic)\n",
    "    dominant_topic = topic_counter.most_common(1)[0][0] if topic_counter else \"Unknown\"\n",
    "    cluster_topics[i] = dominant_topic  \n",
    "\n",
    "    # Assign dominant topic and cluster ID to each node\n",
    "    for repo in cluster:\n",
    "        G.nodes[repo][\"category\"] = dominant_topic\n",
    "        G.nodes[repo][\"cluster_id\"] = i  \n",
    "\n",
    "# Generate distinct colors for clusters\n",
    "num_clusters = len(top_clusters)\n",
    "colors = plt.cm.get_cmap(\"tab20\", num_clusters)\n",
    "\n",
    "# Assign colors to clusters\n",
    "cluster_colors = {\n",
    "    i: f\"#{int(colors(i)[0]*255):02x}{int(colors(i)[1]*255):02x}{int(colors(i)[2]*255):02x}\" \n",
    "    for i in range(num_clusters)\n",
    "}\n",
    "\n",
    "# Assign color attribute to each node\n",
    "for i, cluster in enumerate(top_clusters):\n",
    "    for repo in cluster:\n",
    "        G.nodes[repo][\"color\"] = cluster_colors[i]\n",
    "\n",
    "# Print Cluster Topics\n",
    "print(\"\\n=== Dominant Topic for Each of the Top 15 Clusters ===\")\n",
    "for cluster_id, topic in cluster_topics.items():\n",
    "    print(f\"Cluster {cluster_id}: {topic}\")\n",
    "\n",
    "# Write the graph to a GEXF file\n",
    "output_file = \"temp/llm_clusters_github.gexf\"\n",
    "nx.write_gexf(G, output_file)\n",
    "print(f\"GEXF file created: {output_file} with cluster, category, color, URL, stars, watchers, forks, primaryLanguage, isFork, isArchived, and license attributes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73da446-4bb7-47bf-a6c8-1754fda7cc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
