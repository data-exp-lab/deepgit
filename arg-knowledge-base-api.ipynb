{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400418bc-83cd-42c1-98de-c783c6787ad0",
   "metadata": {},
   "source": [
    "# DeepGit: Building Edges one Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a1526-c70a-43ef-933e-898e3035f978",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7df1303-580c-4488-a0b3-f0c5bad1b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63a5cb5-187e-46f6-8c3f-945d9598ac11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d77c45-34e4-4096-83ce-c8d421215693",
   "metadata": {},
   "source": [
    "### GitHub Authenticate Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987c520-eb1f-44dd-92fe-7bb4b70ef475",
   "metadata": {},
   "source": [
    "Create a `.env` file in the root directory and add the line `GITHUB_TOKEN = \"your_token\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c133bcc4-71ce-44c6-9558-6a3f07990203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_github(token):\n",
    "    \"\"\"\n",
    "    Returns headers required for GitHub API requests.\n",
    "    The Accept header includes the preview for topics.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Authorization': f'token {token}',\n",
    "        'Accept': 'application/vnd.github.mercy-preview+json'\n",
    "    }\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = authenticate_github(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbcaf7-a703-4a35-89a7-5dace41a732e",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8f7a4-dee5-4114-be8a-1f5c0aac753e",
   "metadata": {},
   "source": [
    "### GitHub Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca789b34-3928-4e7e-a962-eb751c905cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_github_repos_by_topic(tag, headers, stars=1):\n",
    "    \"\"\"\n",
    "    Searches GitHub repositories that have the specified topic (tag) and over 100 stars.\n",
    "    Handles pagination and returns a list of dictionaries containing only the repository name and repo id.\n",
    "    \"\"\"\n",
    "    repos = []\n",
    "    page = 1\n",
    "    per_page = 100\n",
    "    query = f\"topic:{tag} stars:>{stars}\"\n",
    "    \n",
    "    while True:\n",
    "        url = (\n",
    "            f\"https://api.github.com/search/repositories?q={query}\"\n",
    "            f\"&sort=stars&order=desc&per_page={per_page}&page={page}\"\n",
    "        )\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching repositories for tag '{tag}': {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        items = data.get('items', [])\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        for item in items:\n",
    "            repos.append(\n",
    "                 item.get(\"full_name\")\n",
    "            )\n",
    "\n",
    "        # Break if fewer than 'per_page' items were returned (i.e. last page)\n",
    "        if len(items) < per_page:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return repos\n",
    "\n",
    "def get_repo_topics(full_name, headers):\n",
    "    \"\"\"\n",
    "    Fetches the topics (tags) of a repository given its full name.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('names', [])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160a51a-f755-466b-9444-ffd54601babb",
   "metadata": {},
   "source": [
    "### Tag Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353d5e38-1e3f-44c8-86b4-388e29addd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic_similarities(model_name: str, given_topic: str, topic_pool: list, threshold: float = 0.8):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between a given topic and a pool of topics, filtering by a threshold.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the SentenceTransformer model (e.g., 'all-MiniLM-L6-v2').\n",
    "        given_topic (str): The topic to compare against the pool.\n",
    "        topic_pool (list): List of topics to compare.\n",
    "        threshold (float): Minimum similarity score to be included in the results (default: 0.8).\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of (topic, similarity) tuples in descending order of similarity.\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Encode the given topic and the pool of topics\n",
    "    given_embedding = model.encode([given_topic])\n",
    "    pool_embeddings = model.encode(topic_pool)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity(given_embedding, pool_embeddings)[0]\n",
    "    \n",
    "    # Pair topics with their similarity scores\n",
    "    topic_similarity_pairs = [topic for topic, sim in zip(topic_pool, similarities) if sim >= threshold]\n",
    "    \n",
    "    # Sort topics by similarity (higher is better)\n",
    "    topic_similarity_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return topic_similarity_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa850a-3fc7-4bf6-bc0f-820c250fe774",
   "metadata": {},
   "source": [
    "### Temp Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57824ef5-558a-4ad8-b526-5603b93db85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(data_list, file_address):\n",
    "    \"\"\"\n",
    "    Writes each item of the given list to a new line in a text file.\n",
    "\n",
    "    :param data_list: List of elements to write to the file.\n",
    "    :param file_address: Path to the file where the list should be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_address, 'w', encoding='utf-8') as file:\n",
    "            for item in data_list:\n",
    "                file.write(f\"{item}\\n\")\n",
    "        print(f\"List successfully written to {file_address}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7515eb-4349-45c9-a981-0855c65f790b",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e844143-91e1-4d72-9bbe-43e2bd71011b",
   "metadata": {},
   "source": [
    "### Input Tag(Topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb42a8b-7215-4253-9355-7245636f7a03",
   "metadata": {},
   "source": [
    "Suppose we have a topic `abstract-argumentation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97151995-3904-4f13-b70e-6ab07f92d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_topic = \"abstract-argumentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e7a95-28af-4f11-867e-74789eb59bfc",
   "metadata": {},
   "source": [
    "### Git the Initial Repos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae9deb-5269-4e55-8143-cad2435e22b2",
   "metadata": {},
   "source": [
    "**Note**: for demonstration Purpose, we only extract repos have more than 10 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb99b59-31b8-4c52-b0fc-d6a7c6e55efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_with_input_topic = search_github_repos_by_topic(input_topic, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f62ffc-0bbe-455a-bee6-7f037a614fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos_with_input_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77f07be-64a3-4451-a0b5-eda00884fc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DennisCraandijk/DL-abstract-argumentation',\n",
       " 'dmitrykazhdan/MARLeME',\n",
       " 'holydrinker/argumentation-framework',\n",
       " 'jspieler/QBAF-Learning']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_with_input_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014d0e2b-19d9-4070-ba2e-3a553ab7dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List successfully written to ./temp/arg_R.txt\n"
     ]
    }
   ],
   "source": [
    "write_list_to_file(repos_with_input_topic, \"./temp/arg_R.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129f013-08c4-42d4-94cb-6a8a11aefa94",
   "metadata": {},
   "source": [
    "### Get the Pool of Topics\n",
    "\n",
    "Now we have a set of repos and we can extract the pool of topics from these repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df4cf2f-819d-4e0f-92e4-ca0950a3de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pool = []\n",
    "for full_name in repos_with_input_topic:\n",
    "    topic_pool = topic_pool + get_repo_topics(full_name, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ed2ac9-4669-4c31-b4c5-a9147faa2cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee7dd2c-6d61-467f-9801-114e446baa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pool_rm_dup = list(set(topic_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ab94fb-d0f1-4fc4-b649-88dffd2f1fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genetic-algorithm',\n",
       " 'abstract-argumentation',\n",
       " 'reinforcement-learning-agent',\n",
       " 'marl',\n",
       " 'graph-neural-networks',\n",
       " 'model-extractor',\n",
       " 'open-ai',\n",
       " 'argumentation-frameworks',\n",
       " 'open-ai-gym',\n",
       " 'reinforcement-learning']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_pool_rm_dup[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "687b2464-c316-456c-b887-7d714aac1fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List successfully written to ./temp/arg_T.txt\n"
     ]
    }
   ],
   "source": [
    "write_list_to_file(topic_pool_rm_dup, \"./temp/arg_T.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684604fa-7990-40f0-88b8-65feb0dc2f61",
   "metadata": {},
   "source": [
    "### Further Process the Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119a629-950e-450b-a7e1-41fd6468b97b",
   "metadata": {},
   "source": [
    "Note:We probably should do this again and again to ensure that the list of tags is thorough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857baa1e-a9a2-4afa-a5b7-4c6222915af6",
   "metadata": {},
   "source": [
    "**Step1: Frequency Fiter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13708bc8-e866-4475-92ee-337fabea61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = Counter(topic_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd222f1f-2b31-4488-88b4-3d862360bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_topic_counts = {topic: count for topic, count in topic_counts.items() if count >= 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27008a67-c035-4f92-99eb-fd8ad3dfef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argumentation-frameworks',\n",
       " 'neural-symbolic-reasoning',\n",
       " 'abstract-argumentation',\n",
       " 'graph-neural-networks',\n",
       " 'deep-learning',\n",
       " 'reinforcement-learning',\n",
       " 'marl',\n",
       " 'multi-agent-reinforcement-learning',\n",
       " 'interpretability',\n",
       " 'explainability',\n",
       " 'model-extraction',\n",
       " 'model-extractor',\n",
       " 'open-ai',\n",
       " 'open-ai-gym',\n",
       " 'knowledge-extraction',\n",
       " 'plug-and-play',\n",
       " 'library',\n",
       " 'reinforcement-learning-agent',\n",
       " 'extracting-interpretable-models',\n",
       " 'lime',\n",
       " 'explanations',\n",
       " 'rl',\n",
       " 'xai',\n",
       " 'artificial-intelligence',\n",
       " 'genetic-algorithm',\n",
       " 'structure-learning']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filtered_topic_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b90d4-8841-4dba-8893-d917f036453d",
   "metadata": {},
   "source": [
    "**Step2: Similarity Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e232fed8-ff9c-42a9-a3fd-2475b4bf6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "similar_topics = compute_topic_similarities(model_name, input_topic, list(filtered_topic_counts.keys()), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d61e931-d058-4c22-aaf9-4ef3fe3fff80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c4a820e-a726-4cb9-9cfa-2a40aa0bbd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argumentation-frameworks', 'abstract-argumentation']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188e3ea-c958-4faf-b8ed-67ff171c01fc",
   "metadata": {},
   "source": [
    "Meanwhile, I am using this prompt in o3-mini\n",
    "`return me relevant tags to {topic}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd995af5-f235-43ac-b96e-4ce6c82747a4",
   "metadata": {},
   "source": [
    "**Step3: Mannually Craft(Human in the Loop)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6a3d499-04c5-4691-805f-9540e69385a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the help of OpenAI O3-Mini\n",
    "similar_topics = [\n",
    " 'argument-maps',\n",
    " 'argumentation',\n",
    " 'argument-mapping',\n",
    " 'argument-mining',\n",
    " 'argumentation-tools',\n",
    " 'argumentation-mining',\n",
    " 'argumentation-theory',\n",
    " 'argumentation-frameworks',\n",
    " 'neural-symbolic-reasoning',\n",
    " 'abstract-argumentation',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44671b18-213a-4b9b-9cb1-3a6d37762b1d",
   "metadata": {},
   "source": [
    "### Get All Possible Repos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aff870-3333-434d-ba75-3fd42d98196f",
   "metadata": {},
   "source": [
    "**\"422\" error means it exceed the GitHub API Rate Limits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14114ea0-4528-454b-b77f-f43df2a33b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_repos = [ ]\n",
    "for topic in similar_topics:\n",
    "    ls_repos = search_github_repos_by_topic(topic, headers, stars=0)\n",
    "    final_list_repos = final_list_repos + ls_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d142759-3c3a-4b26-98f3-b7d5fc0057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_rm_dup = list(set(final_list_repos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b755ce0-43ca-4822-8c3a-a62402b57821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list_rm_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fcec34-e625-4019-a83b-148f8b43dba4",
   "metadata": {},
   "source": [
    "### Extract All Possible Information for a Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b80eb019-9882-46b9-a01b-dd083b3cb326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to fetch repository details\n",
    "def get_repo_data(repo_name, headers):\n",
    "    url = f\"https://api.github.com/repos/{repo_name}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching repo {repo_name}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# List of repositories (ensure full names: 'owner/repo')\n",
    "repo_data = []\n",
    "for repo in final_list_rm_dup:\n",
    "    repo_info = get_repo_data(repo, headers)\n",
    "    if repo_info:\n",
    "        repo_data.append(repo_info)  # Stores full JSON response\n",
    "\n",
    "# Convert list of dictionaries into DataFrame\n",
    "df_repos = pd.DataFrame(repo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ddf1f3-6c86-4895-b289-187df710320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos.to_csv(\"./temp/arg_kb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
